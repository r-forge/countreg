---
title: "Zero-augmented models"
format: html
bibliography: countreg.bib
number-sections: true
crossref:
  eq-prefix: ""
---

{{< include _preliminaries.qmd >}}

## Hurdle models

In addition to over-dispersion, many empirical count data sets
exhibit more zero observations than would be allowed for
by the Poisson model. One model class capable of capturing
both properties is the hurdle model, 
originally proposed by @countreg:Mullahy:1986 in the econometrics literature
[see @countreg:Cameron+Trivedi:1998; @countreg:Cameron+Trivedi:2005 for an overview].
They are two-component models:
A truncated count component, such as Poisson, geometric or negative binomial,
is employed for positive counts, and
a hurdle component models zero vs. larger counts.
For the latter, either a binomial model or a censored count distribution can be employed.

More formally, the hurdle model combines a count data model 
$f_\mathrm{count}(y; x, \beta)$ (that is left-truncated at $y = 1$) and a 
zero hurdle model $f_\mathrm{zero}(y; z, \gamma)$ (right-censored at $y = 1$):
$$
f_\mathrm{hurdle}(y; x, z, \beta, \gamma) =
  \left\{
  \begin{array}{ll}
  f_\mathrm{zero}(0; z, \gamma) & \mbox{if } y = 0, \\
  (1 - f_\mathrm{zero}(0; z, \gamma)) \cdot
  f_\mathrm{count}(y; x, \beta)/(1 - f_\mathrm{count}(0; x, \beta)) & \mbox{if } y > 0
  \end{array}
  \right.
$$ {#eq-hurdle}
The model parameters $\beta$, $\gamma$, and potentially one or two additional
dispersion parameters $\theta$
(if $f_\mathrm{count}$ or $f_\mathrm{zero}$ or both are negative binomial densities)
are estimated by ML, where the specification of the likelihood has the advantage that
the count and the hurdle component can be maximized separately. The corresponding
mean regression relationship is given by
$$
\log(\mu_i) \quad = \quad x_i^\top \beta +
                    \log(1 - f_\mathrm{zero}(0; z_i, \gamma)) -
		    \log(1 - f_\mathrm{count}(0; x_i, \beta)),
$$ {#eq-hurdle-mean}
again using the canonical log link.
For interpreting the zero model as a hurdle, a binomial GLM is probably the most 
intuitive specification\footnote{Note that
binomial logit and censored geometric models as the hurdle part both lead to 
the same likelihood function and thus to the same coefficient estimates [@countreg:Mullahy:1986].}.
Another useful interpretation arises if the same regressors $x_i = z_i$ are
used in the same count model in both components $f_\mathrm{count} = f_\mathrm{zero}$: 
A test of the hypothesis $\beta = \gamma$ then tests whether the hurdle is
needed or not.

In R, hurdle count data models can be fitted with the
`hurdle()` function from the **countreg** package [@countreg:Zeileis+Kleiber:2013].
Both its fitting function and the returned model objects of class `hurdle`
are modelled after the corresponding GLM functionality in R. The
arguments of `hurdle()` are given by

```
hurdle(formula, data, subset, na.action, weights, offset,
  dist = "poisson", zero.dist = "binomial", link = "logit",
  control = hurdle.control(...),
  model = TRUE, y = TRUE, x = FALSE, ...)
```

where the first line contains the standard model-frame specifications,
the second and third lines have the arguments specific to hurdle models and
the arguments in the last line control some components of the return value.

If a `formula` of type `y ~ x1 + x2` is supplied, it not only
describes the count regression relationship of $y_i$ and $x_i$ but also implies that
the same set of regressors is used for the zero hurdle component $z_i = x_i$.
This is could be made more explicit by equivalently writing the formula as
`y ~ x1 + x2 | x1 + x2`. Of course, a different set of regressors
could be specified for the zero hurdle component, e.g.,
`y ~ x1 + x2 | z1 + z2 + z3`, giving the count data model `y ~ x1 + x2`
conditional on (`|`) the zero hurdle model `y ~ z1 + z2 + z3`.

The model likelihood can be specified by the `dist`, `zero.dist` and `link` arguments.
The count data distribution `dist` is `"poisson"` by default (it
can also be set to `"negbin"` or `"geometric"`), for which the canonical log link
is always used. The distribution for the zero hurdle model can be specified via
`zero.dist`. The default is a binomial model with `link` (defaulting
to `"logit"`, but all link functions of the `binomial()` family are also supported),
alternatively a right-censored count distribution (Poisson,
negative binomial or geometric, all with log link) could be specified.

ML estimation of all parameters employing analytical gradients is carried out
using R's `optim()` with control options set in `hurdle.control()`.
Starting values can be user-supplied, otherwise they are estimated by `glm.fit()`
(the default). The covariance matrix estimate is derived numerically using
the Hessian matrix returned by `optim()`.
See @sec-hurdle for further technical details.

The returned fitted-model object of class `hurdle` is a list similar
to `glm` objects. Some of its elements---such as `coefficients` or
`terms`---are lists with a zero and count component,
respectively. For details see @sec-hurdle.

A set of standard extractor functions for fitted model objects is available for
objects of class `hurdle`, including the usual `summary()` method that
provides partial Wald tests for all coefficients. No `anova()` method is provided,
but the general `coeftest()`, `waldtest()` from **lmtest**, and `linearHypothesis()`
from **car** can be used for Wald tests and `lrtest()` from **lmtest**
for LR tests of nested models. The function `hurdletest()` is a convenience
interface to `linearHypothesis()` for testing for the presence of a hurdle
(which is only applicable if the same regressors and the same count distribution
are used in both components).


## Zero-inflated models

Zero-inflated models [@countreg:Mullahy:1986; @countreg:Lambert:1992]
are another model class capable of dealing with excess zero counts 
\citep[see][for an overview]{countreg:Cameron+Trivedi:1998,countreg:Cameron+Trivedi:2005}.
They are two-component mixture models
combining a point mass at zero with a count distribution such as
Poisson, geometric or negative binomial. Thus, there are two
sources of zeros: zeros may come from both the point mass and
from the count component. For modeling the unobserved state
(zero vs. count), a binary model is used: in the simplest case
only with an intercept but potentially containing regressors.

Formally, the zero-inflated density is a mixture of a point mass
at zero $I_{\{0\}}(y)$ and a count distribution $f_\mathrm{count}(y; x, \beta)$.
The probability of observing a zero count is inflated with probability
$\pi = f_\mathrm{zero}(0; z, \gamma)$:
$$
f_\mathrm{zeroinfl}(y; x, z, \beta, \gamma) \quad = \quad
  f_\mathrm{zero}(0; z, \gamma) \cdot I_{\{0\}}(y) \; + \;
  (1 - f_\mathrm{zero}(0; z, \gamma)) \cdot f_\mathrm{count}(y; x, \beta),
$$ {#eq-zeroinfl}
where $I(\cdot)$ is the indicator function and the unobserved probability $\pi$
of belonging to the point mass component is modelled by a binomial GLM
$\pi =  g^{-1}(z^\top \gamma)$.
The corresponding regression equation for the mean is
$$
\mu_i \quad = \quad \pi_i \cdot 0 \; + \; (1 - \pi_i) \cdot \exp(x_i^\top \beta),
$$ {#eq-zeroinfl-mean}
using the canonical log link.
The vector of regressors in the zero-inflation model $z_i$
and the regressors in the count component $x_i$ need not to be distinct---in
the simplest case, $z_i = 1$ is just
an intercept. The default link function $g(\pi)$ in binomial GLMs is the
logit link, but other links such as the probit are also available. The full
set of parameters of $\beta$, $\gamma$, and potentially the dispersion parameter $\theta$ (if 
a negative binomial count model is used) can be estimated by ML. Inference
is typically performed for $\beta$ and $\gamma$, while $\theta$ is treated
as a nuisance parameter even if a negative binomial model is used.

In R, zero-inflated count data models can be fitted with the
`zeroinfl()` function from the **countreg** package. Both 
the fitting function interface and the returned model objects of class `zeroinfl`
are almost identical to the corresponding `hurdle()` functionality and again
modelled after the corresponding GLM functionality in R. The
arguments of `zeroinfl()` are given by

```
zeroinfl(formula, data, subset, na.action, weights, offset,
  dist = "poisson", link = "logit", control = zeroinfl.control(...),
  model = TRUE, y = TRUE, x = FALSE, ...)
```

where all arguments have almost the same meaning as for `hurdle()`. The main
difference is that there is no `zero.dist` argument: a binomial model is
always used for distribution in the zero-inflation component.

Again, ML estimates of all parameters are obtained from `optim()`,
with control options set in `zeroinfl.control()` and employing analytical gradients.
Starting values can be user-supplied, estimated by the expectation maximization (EM)
algorithm, or by `glm.fit()` (the default).
The covariance matrix estimate is derived numerically using
the Hessian matrix returned by `optim()`. Using EM estimation for
deriving starting values is typically slower but can be numerically more stable.
It already maximizes the likelihood, but a single `optim()` iteration is used
for determining the covariance matrix estimate.
See @sec-zeroinfl for further technical details.

The returned fitted model object is of class `zeroinfl` whose structure
is virtually identical to that of `hurdle` models. As above,
a set of standard extractor functions for fitted model objects is available for
objects of class `zeroinfl`, including the usual `summary()` method that
provides partial Wald tests for all coefficients. Again, no `anova()` method is provided,
but the general functions `coeftest()` and `waldtest()` from **lmtest**,
as well as `linearHypothesis()` from **car** can be used for Wald tests,
and `lrtest()` from **lmtest** for LR tests of nested models. 


## Illustrations {#sec-illustrations}

In the following, we illustrate hurdle and zero-inflated models by applying
them to the cross-sectional data set used in @countreg:Deb+Trivedi:1997. It is 
based on the US National Medical Expenditure Survey (NMES) for 1987/88 and is
available from the data archive of the _Journal of Applied Econometrics_ at
<https://journaldata.zbw.eu/dataset/demand-for-medical-care-by-the-elderly-a-finite-mixture-approach>. 
It was prepared for the R package **AER** accompanying
@countreg:Kleiber+Zeileis:2008 and is also available as `DebTrivedi.rda` in the
_Journal of Statistical Software_ together with @countreg:Zeileis:2006. The same
data set is used to illustrate some basic count data models in the article
["Basics"](basics.qmd#sec-illustrations), which further contains a more detailed
description and a basic exploratory analysis of the data.

The objective is to model the number of physician office visits `visits`
using the health status variables
`health` (self-perceived health status),
`chronic` (number of chronic conditions),
as well as the socio-economic variables
`gender`,
`school` (number of years of education), and
`insurance` (private insurance indicator) as regressors. For convenience, we
select the variables used from the full data set:

```{r dt_notrun}
data("NMES1988", package = "AER")
dt <- NMES1988[, c(1, 7, 8, 13, 15, 18)]
```

At the end, we will provide a brief comparison between the zero-adjusted models
and the basic count data models illustrated in
["Basics"](basics.qmd#sec-illustrations).


### Hurdle regression

The exploratory analysis in ["Basics"](basics.qmd#sec-illustrations) conveyed 
the impression that there might be more zero observations
than explained by the basic count data distributions, hence a negative
binomial hurdle model is fitted via
```{r hurdle0}
#| eval: false
fm_hurdle0 <- hurdle(visits ~ ., data = dt, dist = "negbin")
```
This uses the same type of count data model as in the preceeding section
but it is now truncated for `visits < 1` and has an additional hurdle
component modeling zero vs. count observations. By default, the hurdle
component is a binomial GLM with logit link which contains all regressors used in the count
model. The associated coefficient estimates and partial Wald tests for
both model components are displayed via
```{r summary-hurdle0}
summary(fm_hurdle0)
```
The coefficients in the count component resemble those from the previous
models, but the increase in the log-likelihood (see also @tbl-summary)
conveys that the model has improved by including the hurdle component.
However, it might be possible to omit the `health` variable from
the hurdle model. To test this hypothesis, the reduced model is fitted
via
```{r hurdle}
#| eval: false

fm_hurdle <- hurdle(visits ~ . | chronic + insurance + school + gender,
  data = dt, dist = "negbin")
```
and can then be compared to the full model in a Wald test
```{r waldtest-hurdle}
waldtest(fm_hurdle0, fm_hurdle)
```
or an LR test
```{r lrtest-hurdle, eval=FALSE}
lrtest(fm_hurdle0, fm_hurdle)
```
which leads to virtually identical results.

```{r summary-table-prep}
#| echo: false
fm_cap <- paste("Summary of fitted count regression models for NMES data",
                '(including the models from ["Basics"](basics.qmd#sec-illustrations)):',
                "coefficient estimates from count model, zero-inflation model",
                "(both with standard errors in parantheses)",
                ", number of estimated parameters, maximized log-likelihood, AIC, BIC",
                "and expected number of zeros (sum of fitted densities evaluated at zero).",
                "The observed number of zeros is", sum(dt$visits < 1), "in",
                nrow(dt), "observations.")

# Modify output of hurdle and zeroinfl models
msedit <- function(x) {
  out <- modelsummary(x, output = "modelsummary_list")
  out$tidy$term <- gsub("count_", "", out$tidy$term) # remove count_ prefix
  out$glance$logLik <- logLik(x) # add loglik
  
  return(out)
}

ms_zero_models <- lapply(list("NB-Hurdle" = fm_hurdle, "ZINB" = fm_zinb), msedit)

## Modify output of hurdle and zeroinfl models
ms_fm_hurdle <- modelsummary(fm_hurdle, output = "modelsummary_list")

# remove count_ prefix for variables
ms_fm_hurdle$tidy$term <- gsub("count_", "", ms_fm_hurdle$tidy$term)

# add loglik
ms_fm_hurdle$glance$logLik <- logLik(fm_hurdle)
```

```{r summary-table}
#| echo: false
#| warning: false
#| label: tbl-summary
#| tbl-cap: !expr fm_cap

fm <- c(list("ML-Pois" = fm_pois, "Adj-Pois" = fm_pois, "Quasi-Pois" = fm_qpois,
           "NB" = fm_nbin), ms_zero_models)
zero_prob <- c("ML-Pois" = round(sum(dpois(0, fitted(fm_pois))), 0),
               "Adj-Pois" = "",
               "Quasi-Pois" = "",
               "NB" = round(sum(dnbinom(0, mu = fitted(fm_nbin),
                                        size = fm_nbin$theta)), 0),
               "NB-Hurdle" = round(sum(predict(fm_hurdle, type = "density", at = 0)), 0),
               "ZINB" = round(sum(predict(fm_zinb, type = "density", at = 0)), 0))

npars <- sapply(fm[-match(c("NB-Hurdle", "ZINB"), names(fm))],
                function(x) attr(logLik(x), "df"))
npars <- c(npars, sapply(list(fm_hurdle, fm_zinb), function(x) attr(logLik(x), "df")))
addrows <- cbind(c("no. of parameters", "$\\sum_{i} \\hat{f}_{i}(0)$"),
                 t(cbind(npars, zero_prob)))
addrows <- as.data.frame(addrows)

# end_coefs <- 2 * length(coef(fm_pois)) + 1
# attr(addrows, "position") <- c(end_coefs, end_coefs + 4)

out <- modelsummary(fm, output = "markdown",
             vcov = c("classical", "robust", "classical", "classical",
                      "classical", "classical"),
             gof_omit = "R2|R2 Adj.|Num.Obs|F|RMSE|Std.Errors", add_rows = addrows)

# remove _zero for parameters in zero part
out@table_dataframe[,1] <- gsub("zero_", "", out@table_dataframe[,1])

# add horizontal line before zero part
tinytable::style_tt(out, i = length(coef(fm_pois))*2, line = "b", line_width = 0.05)

```


### Comparison

Having fitted several count data regression models to the demand for medical care
in the NMES data, it is, of course, of interest to understand what these models have
in common and what their differences are. In this section, we show how to compute
the components of @tbl-summary and provide some further comments and
interpretations. 

As a first comparison, it is of natural
interest to inspect the estimated regression coefficients in the count data model

```{r coef-count, results='hide'}
fm <- list("ML-Pois" = fm_pois, "Quasi-Pois" = fm_qpois, "NB" = fm_nbin,
  "Hurdle-NB" = fm_hurdle, "ZINB" = fm_zinb)
sapply(fm, function(x) coef(x)[1:7])
```

The result (see @tbl-summary) shows that there are some small differences,
especially between the GLMs and the
zero-augmented models. However, the zero-augmented models have to be interpreted 
slightly differently: While the GLMs all have the same mean function ($g(\mu_i) \quad = \quad x_i^\top \beta$, see ["Basics"](basics.qmd)),
the zero-augmentation also enters the mean function, see (@eq-zeroinfl-mean) and
(@eq-hurdle-mean). Nevertheless,
the overall impression is that the estimated mean functions are rather similar.
Moreover, the associated estimated standard errors
are very similar as well (see @tbl-summary):
```{r se-count, results='hide'}
cbind("ML-Pois" = sqrt(diag(vcov(fm_pois))),
  "Adj-Pois" = sqrt(diag(sandwich(fm_pois))),
  sapply(fm[-1], function(x) sqrt(diag(vcov(x)))[1:7]))
```
The only exception are the model-based standard errors for the Poisson model,
when treated as a fully specified model, which is obviously not appropriate for this data set.

In summary, the models are not too different with respect to their fitted 
mean functions. The differences become obvious if not only the mean but the
full likelihood is considered:
```{r logLik}
rbind(logLik = sapply(fm, function(x) round(logLik(x), digits = 0)),
  Df = sapply(fm, function(x) attr(logLik(x), "df")))
```
The ML Poisson model is clearly inferior to all other fits. The quasi-Poisson
model and the sandwich-adjusted Poisson model are not associated with a fitted
likelihood. The negative binomial already improves the fit dramatically but
can in turn be improved by the hurdle and zero-inflated models which give
almost identical fits. This also reflects that the over-dispersion in the data
is captured better by the negative-binomial-based models than the plain
Poisson model. Additionally, it is of interest how the zero counts
are captured by the various models. Therefore, the observed zero counts are
compared to the expected number of zero counts for the likelihood-based models:
```{r zero-counts}
round(c("Obs" = sum(dt$visits < 1),
  "ML-Pois" = sum(dpois(0, fitted(fm_pois))),
  "NB" = sum(dnbinom(0, mu = fitted(fm_nbin), size = fm_nbin$theta)),
  "NB-Hurdle" = sum(predict(fm_hurdle, type = "density", at = 0)),
  "ZINB" = sum(predict(fm_zinb, type = "density", at = 0))))
```
Thus, the ML Poisson model is again not appropriate whereas the negative-binomial-based
models are much better in modeling the zero counts. By construction, the
expected number of zero counts in the hurdle model matches the observed
number.

In summary, the hurdle and zero-inflation models lead to the best 
results (in terms of likelihood) on this data set. Above, their mean function for the
count component was already shown to be very similar, below we take a
look at the fitted zero components:
```{r coef-zero}
t(sapply(fm[4:5], function(x) round(x$coefficients$zero, digits = 3)))
```
This shows that the absolute values are rather different---which is not
surprising as they pertain to slightly different ways of modeling zero
counts---but the signs of the coefficients match, i.e., are just inversed.
For the hurdle model, the zero hurdle component describes the probability
of observing a positive count whereas, for the ZINB model, the zero-inflation
component predicts the probability of observing a zero count from the
point mass component. Overall, both models lead to the same qualitative
results and very similar model fits. Perhaps the hurdle model is slightly
preferable because it has the nicer interpretation: there is one process
that controls whether a patient sees a physician or not, and a second 
process that determines how many office visits are made.


## Technical details for hurdle models {#sec-hurdle}

The fitting of hurdle models via ML in `hurdle()` is controlled by
the arguments in the `hurdle.control()` wrapper function:

```
hurdle.control(method = "BFGS", maxit = 10000, trace = FALSE,
  separate = TRUE, start = NULL, ...)
```

This modifies some default arguments passed on to the optimizer `optim()`,
such as `method`, `maxit` and `trace`. The latter is also
used within `hurdle()` and can be set to produce more verbose output
concerning the fitting process. The argument `separate` controls
whether the two components of the model are optimized separately (the default)
or not. This is possible because there are no mixed sources for the zeros
in the data (unlike in zero-inflation models). The argument `start`
controls the choice of starting values for calling `optim()`, all remaining
arguments passed through `...` are directly passed on to `optim()`.

By default, starting values are estimated by calling `glm.fit()` for
both components of the model separately, once for the counts and once
for zero vs. non-zero counts. If starting values are supplied,
`start` needs to be set to a named list with the parameters for the
`$count` and `$zero` part of the model (and potentially a
`$theta` dispersion parameter if a negative binomial distribution is used).

The fitted model object of class `hurdle` is similar to `glm`
objects and contains sufficient information on all aspects of the fitting
process. In particular, the estimated parameters and associated covariances
are included as well as the result from the `optim()` call. Furthermore,
the call, formula, terms structure etc. is contained, potentially also the
model frame, dependent variable and regressor matrices.

Following `glm.nb()`, the $\theta$ parameter of the negative binomial
distribution is treated as a nuisance parameter. Thus, the `$coefficients`
component of the fitted model object just contains estimates of
$\beta$ and $\gamma$ while the estimate of $\theta$ and its standard deviation 
(on a log scale) are kept in extra list elements `$theta` and `$SE.logtheta`.


## Technical details for zero-inflated models {#sec-zeroinfl}

Both the interface of the `zeroinfl()` function as well as its fitted
model objects are virtually identical to the corresponding `hurdle`
functionality. Hence, we only provide some additional information for
those aspects that differ from those discussed above. The details of the
ML optimization are again provided by a `zeroinfl.control()` wrapper:

```
zeroinfl.control(method = "BFGS", maxit = 10000, trace = FALSE,
  EM = FALSE, start = NULL, ...)
```

The only new argument here is the argument `EM` which allows for EM
estimation of the starting values. Instead of calling `glm.fit()` only once for
both components of the model, this process can be iterated until convergence of the
parameters to the ML estimates. The optimizer is still called subsequently
(for a single iteration) to obtain the Hessian matrix from which the estimated
covariance matrix can be computed.
